{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c71afd70-e978-452f-8fee-cf465a568f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from docx import Document\n",
    "from docx.shared import Pt\n",
    "from docx.enum.text import WD_ALIGN_PARAGRAPH\n",
    "import subprocess\n",
    "from docx.shared import Pt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "from zipfile import ZipFile \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d37b629b-1591-498e-969a-f63c67a48814",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MailMerge():\n",
    "    def __init__(self, dataset ,label):\n",
    "        self.dataset = dataset\n",
    "        self.label = label\n",
    "\n",
    "    def row_to_pdf(self, data):\n",
    "        for i in data.keys():\n",
    "            if str(data.get(i)) == 'nan':\n",
    "                data[i] = ''\n",
    "                \n",
    "        f = open('template.docx', 'rb')\n",
    "        doc = Document(f)\n",
    "        \n",
    "        ## General Information\n",
    "        doc.tables[0].cell(0, 1).text = data['doctor_name']\n",
    "        doc.tables[0].cell(1, 1).text = data['doctor_department']\n",
    "        doc.tables[0].cell(2, 1).text = data['doctor_sip']\n",
    "        doc.tables[0].cell(3, 1).text = data['doctor_str']\n",
    "        doc.tables[0].cell(0, 3).text = data['name']\n",
    "        doc.tables[0].cell(1, 3).text = data['gender']\n",
    "        doc.tables[0].cell(2, 3).text = data['dob']\n",
    "        doc.tables[0].cell(3, 3).text = str(data['card_no']).replace('.0', '')\n",
    "        doc.tables[0].cell(4, 3).text = data['payor']\n",
    "        doc.tables[0].cell(5, 3).text = data['corporate']\n",
    "        \n",
    "        for i in range(6):\n",
    "            if i < 4:\n",
    "                doc.tables[0].cell(i, 1).paragraphs[0].runs[0].font.size = Pt(8)\n",
    "            doc.tables[0].cell(i, 3).paragraphs[0].runs[0].font.size = Pt(8)\n",
    "        \n",
    "        ## complaint & diagnosis\n",
    "        doc.paragraphs[2].text = data['chief_complaints']\n",
    "        doc.paragraphs[2].runs[0].font.size= Pt(8)\n",
    "        doc.paragraphs[4].text = str(data['diagnosis']) if str(data['diagnosis']) != '' else '' + (', ' + str(data['suggestion'])) if str(data['suggestion']) != '' else '' \n",
    "        doc.paragraphs[4].runs[0].font.size= Pt(8)\n",
    "        \n",
    "        doc.paragraphs[6].text = data['icdx']\n",
    "        doc.paragraphs[6].runs[0].font.size= Pt(8)\n",
    "        \n",
    "        ## Consultation Detail\n",
    "        doc.tables[1].cell(1, 1).text = str(data['consult_id']).replace('.0', '')\n",
    "        doc.tables[1].cell(1, 2).text = str(data['claim_id']).replace('.0', '')\n",
    "        doc.tables[1].cell(1, 3).text = data['date'].strftime('%d/%m/%Y') + ' ' + data['time']\n",
    "        doc.tables[1].cell(1, 4).text = 'IDR '+ str(data['consult_fee']).replace('.0', '')\n",
    "        doc.tables[1].cell(1, 7).text = 'IDR '+ str(data['consult_fee']).replace('.0', '')\n",
    "        doc.tables[1].cell(2, 1).text = str(data['order_id']).replace('.0', '')\n",
    "        \n",
    "        \n",
    "        doc.tables[1].cell(1, 1).paragraphs[0].runs[0].font.size= Pt(8)\n",
    "        doc.tables[1].cell(1, 2).paragraphs[0].runs[0].font.size= Pt(8)\n",
    "        doc.tables[1].cell(1, 3).paragraphs[0].runs[0].font.size= Pt(8)\n",
    "        doc.tables[1].cell(1, 4).paragraphs[0].runs[0].font.size= Pt(8)\n",
    "        doc.tables[1].cell(1, 7).paragraphs[0].runs[0].font.size= Pt(8)\n",
    "        doc.tables[1].cell(2, 1).paragraphs[0].runs[0].font.size= Pt(8)\n",
    "        \n",
    "        for i in range(1,13):\n",
    "            j = i + 2\n",
    "            if str(data[f'obat_{i}']) != '':\n",
    "                doc.tables[1].cell(j, 0).text = data[f'obat_{i}']\n",
    "                doc.tables[1].cell(j, 0).paragraphs[0].alignment = 2\n",
    "                doc.tables[1].cell(j, 4).text = 'IDR '+ str(data[f'total_{i}']).replace('.0', '')\n",
    "                doc.tables[1].cell(j, 5).text = str(data[f'jumlah_{i}']).replace('.0', '')\n",
    "                doc.tables[1].cell(j, 6).text = data[f'unit_obat_{i}']\n",
    "                doc.tables[1].cell(j, 7).text = 'IDR '+ str(data[f'total_{i}']).replace('.0', '')\n",
    "        \n",
    "                doc.tables[1].cell(j, 6).paragraphs[0].runs[0].italic = True\n",
    "                \n",
    "                doc.tables[1].cell(j, 0).paragraphs[0].runs[0].font.size= Pt(8)\n",
    "                doc.tables[1].cell(j, 4).paragraphs[0].runs[0].font.size= Pt(8)\n",
    "                doc.tables[1].cell(j, 5).paragraphs[0].runs[0].font.size= Pt(8)\n",
    "                doc.tables[1].cell(j, 6).paragraphs[0].runs[0].font.size= Pt(8)\n",
    "                doc.tables[1].cell(j, 7).paragraphs[0].runs[0].font.size= Pt(8)\n",
    "        \n",
    "        doc.tables[1].cell(16, 4).text = 'IDR 0' if data['excess_delivery_fee'] =='' else 'IDR '+ str(data['excess_delivery_fee']).replace('.0', '')\n",
    "        doc.tables[1].cell(16, 7).text = 'IDR 0' if data['excess_delivery_fee'] =='' else 'IDR '+ str(data['excess_delivery_fee']).replace('.0', '')\n",
    "        doc.tables[1].cell(18, 7).text = 'IDR '+ str(data['total']).replace('.0', '')\n",
    "        excess =  0 if  data['rx_excess'] == '' else float(data['rx_excess']) + 0 if  data['excess_consult'] == '' else data['excess_consult']\n",
    "        doc.tables[1].cell(19, 7).text = 'IDR '+ str(data['total'] - excess).replace('.0', '')\n",
    "        doc.tables[1].cell(20, 7).text = 'IDR '+ str(excess).replace('.0', '')\n",
    "        \n",
    "        doc.tables[1].cell(16, 4).paragraphs[0].runs[0].font.size= Pt(8)\n",
    "        doc.tables[1].cell(16, 7).paragraphs[0].runs[0].font.size= Pt(8)\n",
    "        doc.tables[1].cell(18, 7).paragraphs[0].runs[0].font.size= Pt(8)\n",
    "        doc.tables[1].cell(19, 7).paragraphs[0].runs[0].font.size= Pt(8)\n",
    "        doc.tables[1].cell(20, 7).paragraphs[0].runs[0].font.size= Pt(8)\n",
    "        \n",
    "        doc.tables[1].cell(18, 7).paragraphs[0].runs[0].bold = True\n",
    "        doc.tables[1].cell(19, 7).paragraphs[0].runs[0].bold = True\n",
    "        doc.tables[1].cell(20, 7).paragraphs[0].runs[0].bold = True\n",
    "        \n",
    "        name = data['name'].replace('/', ' ')\n",
    "        consult_on = data['date'].strftime('%Y-%m-%d')\n",
    "        consult_id = str(data['consult_id']).replace('.0', '')\n",
    "        agg = data['aggregator_name']\n",
    "        payor = data['payor']\n",
    "        \n",
    "        if not os.path.exists(f'.tmp/{self.label}/{agg}/{payor}'):\n",
    "            os.makedirs(f'.tmp/{self.label}/{agg}/{payor}')\n",
    "        \n",
    "        \n",
    "        tmp_name = f'.tmp/{self.label}/{agg}/{payor}/{consult_on}_Consultation_Receipt_{name}_{consult_id}.docx'\n",
    "        doc.save(tmp_name)\n",
    "        f.close()\n",
    "        \n",
    "        subprocess.run(['libreoffice', '--convert-to', 'pdf' ,\n",
    "                        tmp_name, '--outdir', f'.tmp/{self.label}/{agg}/{payor}']\n",
    "                       ,stdout=subprocess.DEVNULL,\n",
    "                        stderr=subprocess.DEVNULL\n",
    "                    )\n",
    "        os.remove(tmp_name)\n",
    "        \n",
    "    def chunks(self, lst, n):\n",
    "        \"\"\"Yield successive n-sized chunks from lst.\"\"\"\n",
    "        for i in range(0, len(lst), n):\n",
    "            yield lst[i:i + n] \n",
    "        \n",
    "    def chunk_and_zip(self):\n",
    "        if not os.path.exists(f'output/{self.label}'):\n",
    "            os.makedirs(f'output/{self.label}')\n",
    "            \n",
    "        fls = glob.glob(f'.tmp/{self.label}/*/*/*')\n",
    "        unique_agg = np.unique([i.split('/')[2] for i in fls])\n",
    "        unique_pay = np.unique([i.split('/')[3] for i in fls])\n",
    "        for i in unique_agg:\n",
    "            for j in unique_pay:\n",
    "                ij = [x for x in fls if x.split('/')[2] == i and x.split('/')[3] == j]\n",
    "                k = 1\n",
    "                for files in self.chunks(ij, 100):\n",
    "                    with ZipFile(f'output/{self.label}/{i}_{j}_{k}.zip','w') as zip: \n",
    "                        for file_each in files:\n",
    "                            zip.write(file_each, file_each.split('/')[-1]) \n",
    "                    k = k + 1\n",
    "                    \n",
    "        fls2 = glob.glob(f'output/{label}/*')\n",
    "        with ZipFile(f'output/{label}.zip','w') as zip:\n",
    "            for file_each in fls2:\n",
    "                zip.write(file_each, file_each.split('/')[-1]) \n",
    "        shutil.rmtree(f'output/{label}')\n",
    "\n",
    "    def run(self):\n",
    "        for index, row in tqdm(self.dataset.iterrows()):\n",
    "            self.row_to_pdf(row)\n",
    "\n",
    "        self.chunk_and_zip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f90995aa-8992-4017-96c8-3ca7094fd3a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/openpyxl/worksheet/_read_only.py:81: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  for idx, row in parser.parse():\n"
     ]
    }
   ],
   "source": [
    "\n",
    "consult = pd.read_excel('Input/04. Report PPU April 2024.xlsx', sheet_name='Discharge Consult')\n",
    "consult.columns = consult.columns.str.lower().str.strip().str.replace('[!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^`{|}~]','', regex = True).str.replace(' ', '_')\n",
    "\n",
    "consult_mrg = pd.read_excel('Input/sample_consult_file_w_prescription_3.xlsx')\n",
    "\n",
    "consult_mrg.columns = consult_mrg.columns.str.lower().str.strip().str.replace('[!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^`{|}~]','', regex = True).str.replace(' ', '_')\n",
    "consult_mrg = consult_mrg.merge(consult[['consultation_id','dob','gender']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "45e9f2b4-d3e1-412d-9fc5-c8407d12f056",
   "metadata": {},
   "outputs": [],
   "source": [
    "consult_mrg['card_no'] = consult_mrg['card_no'].astype(str)\n",
    "consult_mrg.to_csv('sample_input.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "78df0067-34f9-4182-a034-66df6ff8e449",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        8000150301320947\n",
       "1        8000150301293037\n",
       "2        8000150301336844\n",
       "3        8000150301311268\n",
       "4        8000150301269417\n",
       "               ...       \n",
       "19738    8360535102147461\n",
       "19739    8360535102147461\n",
       "19740    8360535102553693\n",
       "19741    8360535102507292\n",
       "19742    8360535202492315\n",
       "Name: card_no, Length: 19743, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "consult_mrg['card_no'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5355297c-23c9-4d49-92b4-fbc62f4ffcb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "consult_mrg = consult_mrg.sort_values(['aggregator_name', 'payor'], ascending = False)\n",
    "payor_stat = consult_mrg['payor'].value_counts().reset_index()\n",
    "pyr = payor_stat[payor_stat['count'] < 2].iloc[:3].payor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2fb39448-02da-471d-ae70-313710c770c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 1000)\n",
    "pd.set_option('display.max_rows', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e9817f72-2acf-4f6a-b604-06bf7843d1ae",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pyr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m z \u001b[38;5;241m=\u001b[39m consult_mrg[consult_mrg[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpayor\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39misin(\u001b[43mpyr\u001b[49m)]\n\u001b[1;32m      2\u001b[0m z\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pyr' is not defined"
     ]
    }
   ],
   "source": [
    "z = consult_mrg[consult_mrg['payor'].isin(pyr)]\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b37afce2-8686-4da0-a09b-1bc6997e3c23",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:09,  3.28s/it]\n"
     ]
    }
   ],
   "source": [
    "MailMerge(z, 'Week1').run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2632dfd2-1f86-4dfb-9112-572d4da323f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunks(lst, n):\n",
    "    \"\"\"Yield successive n-sized chunks from lst.\"\"\"\n",
    "    for i in range(0, len(lst), n):\n",
    "        yield lst[i:i + n] \n",
    "            \n",
    "def chunk_and_zip(label):\n",
    "    if not os.path.exists(f'output/{label}'):\n",
    "        os.makedirs(f'output/{label}')\n",
    "    else:\n",
    "        shutil.rmtree(f'output/{label}')\n",
    "\n",
    "    if os.path.exists(f'output/{label}.zip'):\n",
    "        os.remove(f'output/{label}.zip')\n",
    "    \n",
    "    fls = glob.glob(f'.tmp/{label}/*/*/*')\n",
    "    unique_agg = np.unique([i.split('/')[2] for i in fls])\n",
    "    unique_pay = np.unique([i.split('/')[3] for i in fls])\n",
    "    for i in unique_agg:\n",
    "        for j in unique_pay:\n",
    "            ij = [x for x in fls if x.split('/')[2] == i and x.split('/')[3] == j]\n",
    "            k = 1\n",
    "            for files in self.chunks(ij, 100):\n",
    "                with ZipFile(f'output/{label}/{i}_{j}_{k}.zip','w') as zip: \n",
    "                    for file_each in files:\n",
    "                        zip.write(file_each, file_each.split('/')[-1]) \n",
    "                k = k + 1\n",
    "    fls2 = glob.glob(f'output/{label}/*')\n",
    "    with ZipFile(f'output/{label}.zip','w') as zip:\n",
    "        for file_each in fls2:\n",
    "            zip.write(file_each)\n",
    "    shutil.rmtree('output/{label}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "81493aeb-46d5-4b7f-915b-24f75f672039",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = 'Week1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d29d6cb0-f192-433c-8c10-f9516f2b5f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "    fls = glob.glob(f'.tmp/{label}/*/*/*')\n",
    "    unique_agg = np.unique([i.split('/')[2] for i in fls])\n",
    "    unique_pay = np.unique([i.split('/')[3] for i in fls])\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4261ac0d-d6fc-4c00-8729-a8575ae45191",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.tmp/Week1/Admedika/HUSKY/2024-04-10_Consultation_Receipt_FARIS SYAUKI_1381139.pdf',\n",
       " '.tmp/Week1/Admedika/ESMAL/2024-04-24_Consultation_Receipt_RAMDHAN SUPRAYOGI_1397955.pdf',\n",
       " '.tmp/Week1/Admedika/ASABRI/2024-04-09_Consultation_Receipt_ANDRY MULYAWAN_1380230.pdf',\n",
       " '.tmp/Week1/Admedika/PANFIC/2024-04-28_Consultation_Receipt_Andrie Batista Azizul Hakim_1401183.pdf',\n",
       " '.tmp/Week1/Admedika/PANFIC/2024-04-27_Consultation_Receipt_Nalam Amala Syauqia_1402406.pdf',\n",
       " '.tmp/Week1/Admedika/PANFIC/2024-04-27_Consultation_Receipt_Ahmad Raihan Fadhil_1402413.pdf',\n",
       " '.tmp/Week1/Admedika/PANFIC/2024-04-27_Consultation_Receipt_Desi Kurniawati_1401944.pdf',\n",
       " '.tmp/Week1/Admedika/PANFIC/2024-04-27_Consultation_Receipt_Muhammad Dhio Haryanto_1402036.pdf',\n",
       " '.tmp/Week1/Admedika/PANFIC/2024-04-28_Consultation_Receipt_Fitri Yuliyanti_1403400.pdf',\n",
       " '.tmp/Week1/Admedika/PANFIC/2024-04-27_Consultation_Receipt_Meilin Bong_1401831.pdf',\n",
       " '.tmp/Week1/Admedika/PANFIC/2024-04-27_Consultation_Receipt_Nayla Ramadhani_1401816.pdf',\n",
       " '.tmp/Week1/Admedika/PANFIC/2024-04-27_Consultation_Receipt_Adi Febryan_1402352.pdf',\n",
       " '.tmp/Week1/Admedika/PANFIC/2024-04-28_Consultation_Receipt_Edo Buci Sindutama_1402911.pdf',\n",
       " '.tmp/Week1/Admedika/PANFIC/2024-04-27_Consultation_Receipt_Arseno Yudho Wibowo_1401765.pdf',\n",
       " '.tmp/Week1/Admedika/PANFIC/2024-04-28_Consultation_Receipt_Candra Sukma Hantiyo_1403111.pdf',\n",
       " '.tmp/Week1/Admedika/PANFIC/2024-04-27_Consultation_Receipt_Suci Pujiandri_1401879.pdf',\n",
       " '.tmp/Week1/Admedika/PANFIC/2024-04-27_Consultation_Receipt_Septian Hardiansyah_1401859.pdf']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80736616-4eee-457e-92f8-31f93e30d034",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jovyan/work'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b269b91d-df27-4a7d-bdb9-f7d370197162",
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree('output')\n",
    "os.mkdir('output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ead328e-6d25-47ea-8a26-478b41e12b53",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
